{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LatinRulesBasedTest",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8BYoyBEYQ5Fd",
        "outputId": "6dda415a-f856-44f2-f7cf-0591cba4252b"
      },
      "source": [
        "!git clone https://github.com/wjbmattingly/text-analysis-for-ancient-and-medieval-languages"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'text-analysis-for-ancient-and-medieval-languages'...\n",
            "remote: Enumerating objects: 208, done.\u001b[K\n",
            "remote: Counting objects: 100% (208/208), done.\u001b[K\n",
            "remote: Compressing objects: 100% (157/157), done.\u001b[K\n",
            "remote: Total 208 (delta 88), reused 154 (delta 37), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (208/208), 14.94 MiB | 18.59 MiB/s, done.\n",
            "Resolving deltas: 100% (88/88), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wNK7H_HVi7nE",
        "outputId": "e1549ba4-4858-4dad-f706-9aa833169124"
      },
      "source": [
        "!pip install spacy==3.0.6"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting spacy==3.0.6\n",
            "  Downloading spacy-3.0.6-cp37-cp37m-manylinux2014_x86_64.whl (12.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.8 MB 57 kB/s \n",
            "\u001b[?25hCollecting typer<0.4.0,>=0.3.0\n",
            "  Downloading typer-0.3.2-py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy==3.0.6) (2.11.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.0.6) (21.2)\n",
            "Collecting thinc<8.1.0,>=8.0.3\n",
            "  Downloading thinc-8.0.13-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (628 kB)\n",
            "\u001b[K     |████████████████████████████████| 628 kB 46.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy==3.0.6) (3.10.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.0.6) (2.23.0)\n",
            "Collecting catalogue<2.1.0,>=2.0.3\n",
            "  Downloading catalogue-2.0.6-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy==3.0.6) (57.4.0)\n",
            "Collecting spacy-legacy<3.1.0,>=3.0.4\n",
            "  Downloading spacy_legacy-3.0.8-py2.py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.0.6) (0.4.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==3.0.6) (3.0.6)\n",
            "Collecting pydantic<1.8.0,>=1.7.1\n",
            "  Downloading pydantic-1.7.4-cp37-cp37m-manylinux2014_x86_64.whl (9.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.1 MB 15.7 MB/s \n",
            "\u001b[?25hCollecting srsly<3.0.0,>=2.4.1\n",
            "  Downloading srsly-2.4.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (451 kB)\n",
            "\u001b[K     |████████████████████████████████| 451 kB 62.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy==3.0.6) (0.8.2)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.0.6) (1.19.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.0.6) (1.0.6)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.0.6) (4.62.3)\n",
            "Collecting pathy>=0.3.5\n",
            "  Downloading pathy-0.6.1-py3-none-any.whl (42 kB)\n",
            "\u001b[K     |████████████████████████████████| 42 kB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==3.0.6) (2.0.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.3->spacy==3.0.6) (3.6.0)\n",
            "Requirement already satisfied: pyparsing<3,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy==3.0.6) (2.4.7)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy==3.0.6) (5.2.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.0.6) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.0.6) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.0.6) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.0.6) (2021.10.8)\n",
            "Requirement already satisfied: click<7.2.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.4.0,>=0.3.0->spacy==3.0.6) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy==3.0.6) (2.0.1)\n",
            "Installing collected packages: catalogue, typer, srsly, pydantic, thinc, spacy-legacy, pathy, spacy\n",
            "  Attempting uninstall: catalogue\n",
            "    Found existing installation: catalogue 1.0.0\n",
            "    Uninstalling catalogue-1.0.0:\n",
            "      Successfully uninstalled catalogue-1.0.0\n",
            "  Attempting uninstall: srsly\n",
            "    Found existing installation: srsly 1.0.5\n",
            "    Uninstalling srsly-1.0.5:\n",
            "      Successfully uninstalled srsly-1.0.5\n",
            "  Attempting uninstall: thinc\n",
            "    Found existing installation: thinc 7.4.0\n",
            "    Uninstalling thinc-7.4.0:\n",
            "      Successfully uninstalled thinc-7.4.0\n",
            "  Attempting uninstall: spacy\n",
            "    Found existing installation: spacy 2.2.4\n",
            "    Uninstalling spacy-2.2.4:\n",
            "      Successfully uninstalled spacy-2.2.4\n",
            "Successfully installed catalogue-2.0.6 pathy-0.6.1 pydantic-1.7.4 spacy-3.0.6 spacy-legacy-3.0.8 srsly-2.4.2 thinc-8.0.13 typer-0.3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AR5yL2GIisZi",
        "outputId": "cfc5e063-1dc5-4a0d-ea58-905d46a8459a"
      },
      "source": [
        "!python -m spacy info"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m\n",
            "============================== Info about spaCy ==============================\u001b[0m\n",
            "\n",
            "spaCy version    3.0.6                         \n",
            "Location         /usr/local/lib/python3.7/dist-packages/spacy\n",
            "Platform         Linux-5.4.104+-x86_64-with-Ubuntu-18.04-bionic\n",
            "Python version   3.7.12                        \n",
            "Pipelines                                      \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DHwhJEGRS3LQ",
        "outputId": "eb09ba97-dddd-4d5d-84bd-30d032d3aace"
      },
      "source": [
        "!spacy download en_core_web_sm"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en-core-web-sm==3.0.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.0.0/en_core_web_sm-3.0.0-py3-none-any.whl (13.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 13.7 MB 2.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy<3.1.0,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from en-core-web-sm==3.0.0) (3.0.6)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.6.1)\n",
            "Requirement already satisfied: typer<0.4.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.3.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (57.4.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.0.6)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.23.0)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.3 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.0.6)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (4.62.3)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.4.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.0.6)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.19.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.11.3)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.3 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (8.0.13)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.0.6)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.4.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (21.2)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.8.2)\n",
            "Requirement already satisfied: pydantic<1.8.0,>=1.7.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.7.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.0.8)\n",
            "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.10.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.3->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.6.0)\n",
            "Requirement already satisfied: pyparsing<3,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.4.7)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (5.2.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2021.10.8)\n",
            "Requirement already satisfied: click<7.2.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.4.0,>=0.3.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.0.1)\n",
            "Installing collected packages: en-core-web-sm\n",
            "  Attempting uninstall: en-core-web-sm\n",
            "    Found existing installation: en-core-web-sm 2.2.5\n",
            "    Uninstalling en-core-web-sm-2.2.5:\n",
            "      Successfully uninstalled en-core-web-sm-2.2.5\n",
            "Successfully installed en-core-web-sm-3.0.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HmKeeqpoTacl"
      },
      "source": [
        "import spacy\n",
        "from spacy.pipeline import EntityRuler\n",
        "import json\n",
        "import glob"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WuOmuENFVtti"
      },
      "source": [
        "def load_data(file):\n",
        "    with open (file, \"r\", encoding=\"utf-8\") as f:\n",
        "        data = json.load(f)\n",
        "    return (data)\n",
        "\n",
        "def write_data(file, data):\n",
        "    with open (file, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(data, f, indent=4)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5XVAyq6ZB8E"
      },
      "source": [
        "def generate_ruler(patterns, name):\n",
        "    nlp = spacy.blank(\"en\")\n",
        "    ruler = nlp.add_pipe(\"entity_ruler\")\n",
        "    ruler.add_patterns(patterns)\n",
        "    ruler.to_disk(f\"/content/text-analysis-for-ancient-and-medieval-languages/models/{name}_ent_ruler/entity_ruler/patterns.jsonl\") \n",
        "    nlp.to_disk(f\"/content/text-analysis-for-ancient-and-medieval-languages/models/{name}_ent_ruler\")"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f94wrVkSZHQ6"
      },
      "source": [
        "def create_training_data(file, type):\n",
        "    data = load_data(file)\n",
        "    patterns = []\n",
        "    for item in data:\n",
        "        pattern = {\n",
        "                    \"label\": type,\n",
        "                    \"pattern\": item\n",
        "                    }\n",
        "        patterns.append(pattern)\n",
        "    return (patterns)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JS-GRP_nZHUC"
      },
      "source": [
        "def test_ent_ruler(ruler, corpus):\n",
        "    nlp = spacy.load(ruler)\n",
        "    with open (corpus, \"r\", encoding=\"utf-8\") as f:\n",
        "        corpus = f.read()\n",
        "    with open (\"/content/text-analysis-for-ancient-and-medieval-languages/temp/results.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "        doc = nlp(corpus)\n",
        "        for ent in doc.ents:\n",
        "            f.write(f\"{ent.text}, {ent.label_}\\n\")"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJ7nnBpNZHXC"
      },
      "source": [
        "person_patterns = create_training_data(\"/content/text-analysis-for-ancient-and-medieval-languages/latin_data/all_names_declined.json\", \"PERSON\")\n",
        "groups_patterns = create_training_data(\"/content/text-analysis-for-ancient-and-medieval-languages/latin_data/groups_declined.json\", \"GROUP\")\n",
        "places_patterns = create_training_data(\"/content/text-analysis-for-ancient-and-medieval-languages/latin_data/places_declined.json\", \"LOCATION\")"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZ7H1dbxZHZs"
      },
      "source": [
        "all_patterns = person_patterns+groups_patterns+places_patterns"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sC9Rp_fCZo1b"
      },
      "source": [
        "generate_ruler(all_patterns, \"latin_loc_per_group\")"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmgyVWADZo4J"
      },
      "source": [
        "test_ent_ruler(\"/content/text-analysis-for-ancient-and-medieval-languages/models/latin_loc_per_group_ent_ruler\", \"/content/text-analysis-for-ancient-and-medieval-languages/latin_data/corpus.txt\")"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s95vZl-yZo6n"
      },
      "source": [
        "def create_training_set(corpus, ent_ruler_model, output_file, prodigy=False):\n",
        "    nlp=spacy.load(ent_ruler_model)\n",
        "    TRAIN_DATA = []\n",
        "    with open (corpus, \"r\", encoding=\"utf-8\") as f:\n",
        "        data = f.read()\n",
        "        segments = data.split(\"\\n\")\n",
        "        for segment in segments:\n",
        "            segment = segment.strip()\n",
        "            doc = nlp(segment)\n",
        "            entities = []\n",
        "            for ent in doc.ents:\n",
        "                if prodigy==True:\n",
        "                    entities.append({\"start\":ent.start_char, \"end\": ent.end_char,  \"label\": ent.label_, \"text\": ent.text})\n",
        "                    pass\n",
        "                else:\n",
        "                    entities.append((ent.start_char, ent.end_char, ent.label_))\n",
        "            if len(entities) > 0:\n",
        "                if prodigy==True:\n",
        "                    TRAIN_DATA.append({\"text\": segment, \"spans\": entities})\n",
        "                else:\n",
        "                    TRAIN_DATA.append([segment, {\"entities\": entities}])\n",
        "    print (len(TRAIN_DATA))\n",
        "    with open (output_file, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(TRAIN_DATA, f, indent=4)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4NOJHW-Zo9A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35c9c0c6-25d6-4e08-f25b-862064171058"
      },
      "source": [
        "create_training_set(\"/content/text-analysis-for-ancient-and-medieval-languages/latin_data/corpus.txt\", \"/content/text-analysis-for-ancient-and-medieval-languages/models/latin_loc_per_group_ent_ruler\", \"/content/text-analysis-for-ancient-and-medieval-languages/training_data/training_set_spacy.json\", prodigy=False)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "388\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTWdeIuiZpEo"
      },
      "source": [
        "from spacy.tokens import DocBin"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxUHsmBZkgr7"
      },
      "source": [
        "all_docs = load_data(\"/content/text-analysis-for-ancient-and-medieval-languages/training_data/training_set_spacy.json\")"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5GmQP6V3kg1N",
        "outputId": "a597333b-7d2a-420f-d5fe-c089497cfe4c"
      },
      "source": [
        "print (all_docs[2])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['[3] His rebus adducti et auctoritate Orgetorigis permoti constituerunt ea quae ad proficiscendum pertinerent comparare, iumentorum et carrorum quam maximum numerum coemere, sementes quam maximas facere, ut in itinere copia frumenti suppeteret, cum proximis civitatibus pacem et amicitiam confirmare. Ad eas res conficiendas biennium sibi satis esse duxerunt; in tertium annum profectionem lege confirmant. Ad eas res conficiendas Orgetorix deligitur. Is sibi legationem ad civitates suscipit. In eo itinere persuadet Castico, Catamantaloedis filio, Sequano, cuius pater regnum in Sequanis multos annos obtinuerat et a senatu populi Romani amicus appellatus erat, ut regnum in civitate sua occuparet, quod pater ante habuerit; itemque Dumnorigi Haeduo, fratri Diviciaci, qui eo tempore principatum in civitate obtinebat ac maxime plebi acceptus erat, ut idem conaretur persuadet eique filiam suam in matrimonium dat. Perfacile factu esse illis probat conata perficere, propterea quod ipse suae civitatis imperium obtenturus esset: non esse dubium quin totius Galliae plurimum Helvetii possent; se suis copiis suoque exercitu illis regna conciliaturum confirmat. Hac oratione adducti inter se fidem et ius iurandum dant et regno occupato per tres potentissimos ac firmissimos populos totius Galliae sese potiri posse sperant.', {'entities': [[580, 588, 'GROUP'], [632, 638, 'GROUP'], [1075, 1083, 'GROUP']]}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BH_qm6cDkg38"
      },
      "source": [
        "train_docs = all_docs[:200]\n",
        "valid_docs = all_docs[200:]"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I36T1REKkg6d",
        "outputId": "fe5818b2-d89d-47f2-95b5-fbf8a684c70b"
      },
      "source": [
        "train_db = DocBin()\n",
        "from tqdm import tqdm\n",
        "nlp = spacy.blank(\"en\")\n",
        "for text, annot in tqdm(train_docs):\n",
        "    doc = nlp.make_doc(text)\n",
        "    ents = []\n",
        "    for start, end, label in annot[\"entities\"]:\n",
        "        span = doc.char_span(start, end, label=label, alignment_mode=\"contract\")\n",
        "        if span is None:\n",
        "            pass\n",
        "        else:\n",
        "            ents.append(span)\n",
        "    doc.ents = ents\n",
        "    train_db.add(doc)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [00:00<00:00, 342.22it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YvJiOI6kkg8u",
        "outputId": "7c74070f-c665-4e30-ecc1-688c7e1922f7"
      },
      "source": [
        "valid_db = DocBin()\n",
        "from tqdm import tqdm\n",
        "nlp = spacy.blank(\"en\")\n",
        "for text, annot in tqdm(valid_docs):\n",
        "    doc = nlp.make_doc(text)\n",
        "    ents = []\n",
        "    for start, end, label in annot[\"entities\"]:\n",
        "        span = doc.char_span(start, end, label=label, alignment_mode=\"contract\")\n",
        "        if span is None:\n",
        "            pass\n",
        "        else:\n",
        "            ents.append(span)\n",
        "    doc.ents = ents\n",
        "    train_db.add(doc)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 188/188 [00:00<00:00, 327.26it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fj3oSw8ZlH3J"
      },
      "source": [
        "train_db.to_disk(\"/content/text-analysis-for-ancient-and-medieval-languages/training_data/train_hs.spacy\")\n",
        "valid_db.to_disk(\"/content/text-analysis-for-ancient-and-medieval-languages/training_data/valid_hs.spacy\")"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vke5XrC-lH6Q",
        "outputId": "b13b6822-8a68-4072-cc7b-4e3e9dbe6f6e"
      },
      "source": [
        "!python -m spacy init fill-config base_config.cfg config.cfg"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
            "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
            "config.cfg\n",
            "You can now add your data and train your pipeline:\n",
            "python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JY3hpeg4lH8s",
        "outputId": "77a366df-0cb0-4e29-afa8-4d9d22d2e941"
      },
      "source": [
        "!python -m spacy train config.cfg --output ./output"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
            "\u001b[1m\n",
            "=========================== Initializing pipeline ===========================\u001b[0m\n",
            "[2021-11-19 14:39:01,437] [INFO] Set up nlp object from config\n",
            "[2021-11-19 14:39:01,449] [INFO] Pipeline: ['tok2vec', 'ner']\n",
            "[2021-11-19 14:39:01,455] [INFO] Created vocabulary\n",
            "[2021-11-19 14:39:01,455] [INFO] Finished initializing nlp object\n",
            "[2021-11-19 14:39:03,195] [INFO] Initialized pipeline components: ['tok2vec', 'ner']\n",
            "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
            "\u001b[1m\n",
            "============================= Training pipeline =============================\u001b[0m\n",
            "\u001b[38;5;4mℹ Pipeline: ['tok2vec', 'ner']\u001b[0m\n",
            "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
            "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
            "---  ------  ------------  --------  ------  ------  ------  ------\n",
            "  0       0          0.00     81.36    0.00    0.00    0.00    0.00\n",
            "  0     200         54.14   2052.07    0.00    0.00    0.00    0.00\n",
            "  1     400         71.68    487.11    0.00    0.00    0.00    0.00\n",
            "  1     600         86.30    210.84    0.00    0.00    0.00    0.00\n",
            "  2     800         85.00    175.18    0.00    0.00    0.00    0.00\n",
            "  2    1000         72.63     92.70    0.00    0.00    0.00    0.00\n",
            "  3    1200         98.82     89.24    0.00    0.00    0.00    0.00\n",
            "  4    1400        100.16     71.54    0.00    0.00    0.00    0.00\n",
            "  5    1600         97.56     57.35    0.00    0.00    0.00    0.00\n",
            "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
            "output/model-last\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5OPtReaBlH_V"
      },
      "source": [
        "nlp = spacy.load(\"output/model-best\")"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFeh0C5l91BJ"
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "soup = BeautifulSoup(open(\"/content/phi0474.phi056.perseus-lat1.xml\"), 'lxml')"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqeV3a1OF5GK"
      },
      "source": [
        "def getSpacyEnts(text):\n",
        "  ent_list = []\n",
        "\n",
        "  doc = nlp(text)\n",
        "  for ent in doc.ents:\n",
        "    ent_list.append((ent.text, ent.label_))\n",
        "  return ent_list"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A4BRHWsBpzpH"
      },
      "source": [
        "# for div in soup.find_all('div'):\n",
        "#   for label in div.find_all('label'):\n",
        "#     for seg in label.find_all('seg'):\n",
        "#       if seg.attrs['rend'] == 'dateline':\n",
        "#         print(getSpacyEnts(seg.text))\n",
        "#   #print(div.attrs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "durKjX6ev0Nl"
      },
      "source": [
        "letter_dict = {}\n",
        "\n",
        "for div in soup.find_all('div'):\n",
        "  try:\n",
        "    if (div.attrs['subtype'] == 'letter'):\n",
        "      letter_dict[f'Letter {div.attrs[\"n\"]}'] = div.text#.replace('\\n\\n', ' ').replace('\\n\\n\\n', ' ')\n",
        "  except: ## filters out first div tag\n",
        "    continue"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "id": "WxjQq5hXyStC",
        "outputId": "1a117b68-ac01-49be-d4b4-3ebab8041f79"
      },
      "source": [
        "letter_dict['Letter 1']"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n\\nScr. in itinere Patris Alyziam iii Non. Nov. a. 704 (50).\\nTVLLIVS TIRONI SVO S. P. D. ET CICERO MEVS ET FRATER ET FRATRIS F.\\n\\n\\nPaulo facilius putavi posse me ferre desiderium tui, sed \\n\\nplane non fero et, quamquam magni ad honorem nostrum interest quam primum ad urbem me venire, tamen peccasse mihi videor qui a te discesserim ; sed quia tua voluntas ea videbatur esse, ut prorsus nisi confirmato corpore nolles navigare, approbavi tuum consilium neque nunc muto, si\\ntu in eadem es sententia ; sin autem, postea quam cibum cepisti, videris tibi posse me consequi, tuum consilium est. Marionem ad te eo misi, ut aut tecum ad me quam primum veniret aut, si tu morarere, statim ad me rediret. \\n\\n\\n\\ntu\\n\\nautem hoc tibi persuade, si commodo valetudinis tuae fieri\\npossit, nihil me malle quam te esse mecum ; si autem intelleges opus esse te Patris convalescendi causa paulum commorari, nihil me malle quam te valere.  si statim navigas, nos Leucade consequere ; sin te confirmare vis, et comites et tempestates et navem idoneam ut habeas diligenter videbis. unum illud, mi Tiro, videto, si me amas, ne te\\nMarionis adventus et hae litterae moveant. quod valetudini tuae maxime conducet si feceris, maxime obtemperaris\\n\\nvoluntati meae. \\n\\n\\n\\nhaec pro tuo ingenio considera.  nos ita\\nte desideramus, ut amemus ; amor ut valentem videamus hortatur, desiderium ut quam primum ; illud igitur potius. cura ergo potissimum ut valeas.  de tuis innumerabilibus in me officiis erit hoc gratissimum.  III non. non\\n\\n\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nVfdTZh6xJWU",
        "outputId": "e112bd2f-0ae5-4860-ae1a-9de46f9a3a7c"
      },
      "source": [
        "getSpacyEnts(letter_dict['Letter 1']) ## Needs tuning, but we're getting there!"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Alyziam', 'PERSON'),\n",
              " ('S.', 'PERSON'),\n",
              " ('P.', 'PERSON'),\n",
              " ('D.', 'PERSON'),\n",
              " ('ET', 'PERSON'),\n",
              " ('ET', 'GROUP'),\n",
              " ('ET', 'GROUP'),\n",
              " ('F.', 'PERSON'),\n",
              " ('Paulo', 'PERSON'),\n",
              " ('Marionem', 'GROUP')]"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    }
  ]
}